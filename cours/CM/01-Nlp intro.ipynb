{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Traitement du Langage Naturel (NLP)\n",
    "\n",
    "![deep](asset/deep.png)\n",
    "\n",
    "# Objectif\n",
    "\n",
    "Le but du NLP est d'exploiter et d'analyser le langage naturel à l'aide de l'intelligence artificielle.\n",
    "Voici une illustration conceptuelle de cette idée :\n",
    "\n",
    "![deep](asset/nlp.png)\n",
    "\n",
    "# Entrées\n",
    "\n",
    "Dans le domaine de la vision par ordinateur, nous utilisons des images comme entrée.\n",
    "\n",
    "Dans d'autres domaines, nous pouvons utiliser des séries temporelles (tableaux de données numériques) comme entrée.\n",
    "\n",
    "**Mais dans le domaine du Traitement du Langage Naturel (NLP), comment transformer du texte en une représentation numérique ?**"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "!pip install -q -U numpy pandas scikit-learn plotly spacy\n",
    "!python -m spacy download en_core_web_sm\n",
    "!python -m spacy download fr_core_news_sm"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 830,
     "status": "ok",
     "timestamp": 1675064120517,
     "user": {
      "displayName": "Swan Blanc",
      "userId": "06655654812785803318"
     },
     "user_tz": -60
    },
    "id": "T4pbXD4m6p5k",
    "outputId": "61349412-0f8e-4fde-b781-efb9a7007db3",
    "ExecuteTime": {
     "end_time": "2025-06-17T12:25:08.926837Z",
     "start_time": "2025-06-17T12:25:07.980446Z"
    }
   },
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "corpus = [\"frites j'aime les frites\", \"LISP c'est trop bien !\", \"j'aime les jeux dragon's Lair\"]\n",
    "\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "print(\"Matrix\", X.toarray())\n",
    "print(\"Vocabulary\", vectorizer.vocabulary_)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix [[1 0 0 0 2 0 0 1 0 0]\n",
      " [0 1 0 1 0 0 0 0 1 1]\n",
      " [1 0 1 0 0 1 1 1 0 0]]\n",
      "Vocabulary {'frites': 4, 'aime': 0, 'les': 7, 'lisp': 8, 'est': 3, 'trop': 9, 'bien': 1, 'jeux': 5, 'dragon': 2, 'lair': 6}\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "77dDKVr8ECpR"
   },
   "source": "En format tableau"
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1087,
     "status": "ok",
     "timestamp": 1675064883703,
     "user": {
      "displayName": "Swan Blanc",
      "userId": "06655654812785803318"
     },
     "user_tz": -60
    },
    "id": "sCeyN-TqDAdJ",
    "outputId": "9ba1cae3-ff19-4716-c397-2930be14b0c5"
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(data=X.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "print(df)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DltJU7DSEydO"
   },
   "source": "Top n mots"
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "executionInfo": {
     "elapsed": 1013,
     "status": "ok",
     "timestamp": 1675064902622,
     "user": {
      "displayName": "Swan Blanc",
      "userId": "06655654812785803318"
     },
     "user_tz": -60
    },
    "id": "ww3ZjBNMEICa",
    "outputId": "c41ca98d-a063-46f9-cd55-78868691f7ad"
   },
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "\n",
    "def get_top_n_words(corpus, n=None):\n",
    "    vec = CountVectorizer().fit(corpus)\n",
    "    bag_of_words = vec.transform(corpus)\n",
    "    sum_words = bag_of_words.sum(axis=0)\n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
    "    words_freq = sorted(words_freq, key=lambda x: x[1], reverse=True)\n",
    "    return words_freq[:n]\n",
    "\n",
    "\n",
    "common_words = get_top_n_words(corpus, 30)\n",
    "df = pd.DataFrame(common_words, columns=['unigram', 'count'])\n",
    "\n",
    "fig = go.Figure([go.Bar(x=df['unigram'], y=df['count'])])\n",
    "fig.update_layout(title=go.layout.Title(text=\"Top 30 unigrams\"))\n",
    "fig.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_gPgdHMfGy3C"
   },
   "source": [
    "## Text similarity"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 233,
     "status": "ok",
     "timestamp": 1675065239603,
     "user": {
      "displayName": "Swan Blanc",
      "userId": "06655654812785803318"
     },
     "user_tz": -60
    },
    "id": "YaLHDHtkG16G",
    "outputId": "6c159c0c-fc80-4fe4-d2d3-2ec7cd0371d9"
   },
   "source": [
    "from sklearn.metrics import jaccard_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Corpus de textes que nous allons utiliser pour trouver des similarités\n",
    "corpus = [\"j'aime les frites\",\n",
    "          \"LISP c'est trop bien !\",\n",
    "          \"j'aime les jeux dragon's Lair\",\n",
    "          \"j'adore les frites\",\n",
    "          \"envoyer un mail\",\n",
    "          \"mangé saussise\"]\n",
    "\n",
    "# Vectorisation du corpus de texte :\n",
    "# Cette étape transforme chaque phrase en un vecteur de caractéristiques où chaque dimension\n",
    "# correspond à un mot unique (caractéristique) présent dans l'ensemble du corpus.\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Apprend le vocabulaire dans le corpus et transforme chaque phrase du corpus en vecteur\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "\n",
    "# Conversion de la matrice sparse générée par scikit-learn en tableau numpy pour une manipulation plus simple\n",
    "arr = X.toarray()\n",
    "\n",
    "\n",
    "def simlarity_search(arr, input_text):\n",
    "    \"\"\"\n",
    "    Fonction qui recherche les phrases les plus similaires dans le corpus en utilisant\n",
    "    le score de similarité de Jaccard.\n",
    "\n",
    "    Arguments :\n",
    "    - arr : tableau numpy des vecteurs représentant le corpus\n",
    "    - input_text : texte d'entrée pour lequel on veut calculer la similarité\n",
    "    \"\"\"\n",
    "    # Vectorisation de la phrase d'entrée :\n",
    "    # Elle est transformée en vecteur pour avoir les mêmes dimensions que ceux du corpus.\n",
    "    input_text = vectorizer.transform([input_text]).toarray()[0]\n",
    "\n",
    "    # Calcul du score de similarité de Jaccard pour chaque phrase du corpus\n",
    "    # Le score de Jaccard compare les similarités entre deux ensembles\n",
    "    # (dans ce cas, les mots des phrases transformés en vecteur).\n",
    "    scores = []\n",
    "    for idx in range(arr.shape[0]):  # Pour chaque vecteur dans le corpus\n",
    "        # Calcul du score de similarité de Jaccard entre la phrase d'entrée et une phrase du corpus\n",
    "        score = jaccard_score(input_text, arr[idx])\n",
    "\n",
    "        # Ajoute le score et la phrase correspondante dans la liste pour un traitement ultérieur\n",
    "        scores.append([score, corpus[idx]])\n",
    "\n",
    "    # Trie des scores par ordre décroissant pour afficher les phrases les plus similaires en premier\n",
    "    scores = sorted(scores, key=lambda x: x[0], reverse=True)\n",
    "\n",
    "    # Affichage des scores et des phrases correspondantes\n",
    "    for score, sentence in scores:\n",
    "        print(f\"{round(score, 2)}: {sentence}\")\n",
    "\n",
    "\n",
    "q1 = \"j'aime manger des frites\"\n",
    "print(f\"Query: {q1}\")\n",
    "# Exécution de la fonction avec un premier texte d'entrée\n",
    "simlarity_search(arr, q1)\n",
    "print(\"----------------------\")\n",
    "q2 = \"envoyé des email\"\n",
    "print(f\"Query: {q2}\")\n",
    "# Exécution de la fonction avec un second texte d'entrée\n",
    "simlarity_search(arr, q2)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Nettoyage des Données (Data Cleaning)\n",
    "\n",
    "Les données textuelles présentent des défis car un même mot peut apparaître sous différentes formes :\n",
    "- **Majuscule/minuscule** : `Chat, chat`\n",
    "- **Conjugaisons** : `aider`, `aidant`, `aidé`, `utile`\n",
    "- **Autres complexités** : la ponctuation et les mots vides (*stop words*) tels que **le**, **que**, **et autres**.\n",
    "\n",
    "**Objectif** : Réduire la variété des mots distincts tout en préservant leur sens essentiel afin de simplifier l'analyse.\n",
    "\n",
    "Nous utiliserons la bibliothèque [spaCy](https://spacy.io) pour nettoyer les données textuelles."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1675065439851,
     "user": {
      "displayName": "Swan Blanc",
      "userId": "06655654812785803318"
     },
     "user_tz": -60
    },
    "id": "r2hc0MfkeADc"
   },
   "source": [
    "corpus = [\"j'aime, les frites\",\n",
    "          \"comment installer un site internet ?\",\n",
    "          \"LISP c'est trop bien !\",\n",
    "          \"j'aime les jeux dragon's Lair\",\n",
    "          \"j'adore les frites\",\n",
    "          \"Envoyer un mail\",\n",
    "          \"mangé: saussise\"]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21323,
     "status": "ok",
     "timestamp": 1675065461160,
     "user": {
      "displayName": "Swan Blanc",
      "userId": "06655654812785803318"
     },
     "user_tz": -60
    },
    "id": "VdsyUqCteOoQ",
    "outputId": "1cb31d5e-66d1-410f-9163-a3a508effe44"
   },
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"fr_core_news_sm\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Tokeniseur\n",
    "L'objectif est de diviser une phrase en tokens (unités lexicales).\n",
    "Par exemple :\n",
    "`I love to play dragon lair` --> `I`, `love`, `to`, `play`, `dragon`, `lair`"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 964,
     "status": "ok",
     "timestamp": 1675065476675,
     "user": {
      "displayName": "Swan Blanc",
      "userId": "06655654812785803318"
     },
     "user_tz": -60
    },
    "id": "mNlSjVffecRl",
    "outputId": "77c7682b-ae05-46df-8364-f3f0d21df6a0"
   },
   "source": [
    "docs = [nlp(sentence) for sentence in corpus]\n",
    "for token in docs[0]:\n",
    "    print(token)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Mots Vides (StopWords)\n",
    "Les mots vides (stop words) sont des mots courants qui apportent peu d'information dans un document texte. Des mots comme `le`, `est`, `un(e)` ont une valeur limitée et ajoutent du bruit aux données textuelles."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 244,
     "status": "ok",
     "timestamp": 1675065516300,
     "user": {
      "displayName": "Swan Blanc",
      "userId": "06655654812785803318"
     },
     "user_tz": -60
    },
    "id": "Nvapb71dfREw",
    "outputId": "9efe9734-d6cb-4668-efbc-90ae0aaf38df"
   },
   "source": [
    "for sentence in docs:\n",
    "    clean_sentence = []\n",
    "    for token in sentence:\n",
    "        if not token.is_stop:\n",
    "            clean_sentence.append(str(token))\n",
    "    print(' '.join(clean_sentence))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cksokCb4gO0W"
   },
   "source": [
    "## Ponctuation\n",
    "\n",
    "Supprimer la ponctuation peut être utile dans certains cas. Cependant, pour d'autres techniques d'encodage, comme celles basées sur l'apprentissage profond, ce n'est généralement pas la meilleure solution."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 237,
     "status": "ok",
     "timestamp": 1675065551649,
     "user": {
      "displayName": "Swan Blanc",
      "userId": "06655654812785803318"
     },
     "user_tz": -60
    },
    "id": "7MNj0njvhHBv",
    "outputId": "23eee26c-38e5-4774-f953-1a7b30bac842"
   },
   "source": [
    "for sentence in docs:\n",
    "    clean_sentence = []\n",
    "    for token in sentence:\n",
    "        if not token.is_stop and not token.is_punct:\n",
    "            clean_sentence.append(str(token))\n",
    "    print(' '.join(clean_sentence))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Lemmatization\n",
    "\n",
    "The goal is to converting a word to its root form  `help`, `helping`, `helped`, `helpful`."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 225,
     "status": "ok",
     "timestamp": 1675065593866,
     "user": {
      "displayName": "Swan Blanc",
      "userId": "06655654812785803318"
     },
     "user_tz": -60
    },
    "id": "XUQd7iGkiYre",
    "outputId": "dc71de96-8b56-4f73-e98b-785483f673f6"
   },
   "source": [
    "for sentence in docs:\n",
    "    clean_sentence = []\n",
    "    for token in sentence:\n",
    "\n",
    "        if token.is_stop or token.is_punct:\n",
    "            continue\n",
    "\n",
    "        if token.lemma_ != \"-PRON-\":\n",
    "            lem_word = token.lemma_.lower()\n",
    "        else:\n",
    "            lem_word = token.lower_\n",
    "\n",
    "        clean_sentence.append(str(lem_word))\n",
    "\n",
    "    print(' '.join(clean_sentence))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aUgD8bcOkoSe"
   },
   "source": [
    "# Bag of words with data cleaning\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "executionInfo": {
     "elapsed": 587,
     "status": "ok",
     "timestamp": 1675065644765,
     "user": {
      "displayName": "Swan Blanc",
      "userId": "06655654812785803318"
     },
     "user_tz": -60
    },
    "id": "dBOdcqoplXPk"
   },
   "source": [
    "clean_sentences = []\n",
    "\n",
    "\n",
    "def clean_sentence(sentence, nlp):\n",
    "    clean_sentence = []\n",
    "    for token in nlp(sentence):\n",
    "\n",
    "        if token.is_stop or token.is_punct:\n",
    "            continue\n",
    "\n",
    "        if token.lemma_ != \"-PRON-\":\n",
    "            lem_word = token.lemma_.lower()\n",
    "        else:\n",
    "            lem_word = token.lower_\n",
    "\n",
    "        clean_sentence.append(str(lem_word))\n",
    "\n",
    "    return ' '.join(clean_sentence)\n",
    "\n",
    "\n",
    "corpus = [\"j'aime les frites\",\n",
    "          \"LISP c'est trop bien !\",\n",
    "          \"j'aime les jeux dragon's Lair\",\n",
    "          \"j'adore les frites\",\n",
    "          \"envoyer un mail\",\n",
    "          \"mangé saussise\"]\n",
    "docs = [clean_sentence(sentence, nlp) for sentence in corpus]\n",
    "docs"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1675065645685,
     "user": {
      "displayName": "Swan Blanc",
      "userId": "06655654812785803318"
     },
     "user_tz": -60
    },
    "id": "XVG1B5bnkyXV",
    "outputId": "3a6357c9-456c-4def-b498-86478cb83e0f"
   },
   "source": [
    "# Vectorise the corpus\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(docs)\n",
    "arr = X.toarray()\n",
    "\n",
    "print(f\"Query: {q1}\")\n",
    "# Exécution de la fonction avec un premier texte d'entrée\n",
    "simlarity_search(arr, clean_sentence(q1, nlp))\n",
    "print(\"----------------------\")\n",
    "print(f\"Query: {q2}\")\n",
    "# Exécution de la fonction avec un second texte d'entrée\n",
    "simlarity_search(arr, clean_sentence(q2, nlp))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# TF-IDF (Fréquence Terme-Inverse de la Fréquence Document)\n",
    "\n",
    "TF-IDF **Vectorizer** et Count **Vectorizer** sont des méthodes utilisées en traitement automatique du langage naturel (NLP) pour transformer du texte en représentations numériques (vectorisation). Cependant, ces deux approches diffèrent fondamentalement :\n",
    "\n",
    "- **CountVectorizer** : Compte simplement le nombre de fois qu'un mot apparaît dans un document (approche sac de mots, ou *bag-of-words*).\n",
    "- **TF-IDF Vectorizer** : Prend en compte la fréquence du mot dans un document mais ajuste cette fréquence en fonction de son importance dans l'ensemble du corpus. Les mots fréquents dans tous les documents (tels que \"le\", \"est\", \"et\") sont pénalisés car ils portent généralement moins d'information.\n",
    "\n",
    "Il n'y a pas une méthode meilleure que l'autre. Le choix dépend du contexte et des besoins de l'application. Tester les deux est une bonne pratique.\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Comment cela fonctionne ?\n",
    "\n",
    "**Tf** signifie *fréquence du terme* (Term Frequency), tandis que **TF-IDF** signifie *fréquence terme* multipliée par *inverse de la fréquence document* :\n",
    "\n",
    "![Bag of Words - Image](./asset/tf_idf_formul.png)\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Terminologie clé\n",
    "\n",
    "- **t** — terme (mot)\n",
    "- **d** — document (ensemble de mots)\n",
    "- **N** — nombre total de documents dans le corpus\n",
    "- **Corpus** — ensemble global de documents\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Fréquence du terme (TF - Term Frequency)\n",
    "\n",
    "La fréquence du terme est calculée comme suit :\n",
    "`tf(t, d) = (nombre d'occurrences de t dans d) / (nombre total de mots dans d)`\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Fréquence Document (DF - Document Frequency)\n",
    "\n",
    "Le nombre de documents où le terme **t** apparaît est appelé fréquence document.\n",
    "`df(t) = nombre de documents contenant t`\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Inverse de la Fréquence Document (IDF)\n",
    "\n",
    "Certains termes comme \"le\", \"est\", \"de\" apparaissent fréquemment mais sont peu informatifs. Pour réduire leur impact, l'inverse de la fréquence document (IDF) est utilisé :\n",
    "\n",
    "`idf(t) = log(N / (df + 1))`\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Formule finale\n",
    "\n",
    "Ainsi, la pondération TF-IDF se calcule comme suit :\n",
    "\n",
    "`tf-idf(t, d) = tf(t, d) * log(N / df)`\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Exemple d'application\n",
    "\n",
    "- **Phrase A** : \"The car is driven on the road.\"\n",
    "- **Phrase B** : \"The truck is driven on the highway.\"\n",
    "\n",
    "(Se référer à l'image associée pour l'exemple pratique.)\n",
    "![TF-IDF - Exemple](./asset/tf_idf_example.png)\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Similarité vectorielle\n",
    "\n",
    "Une fois que chaque document est représenté sous forme de vecteurs dans un espace multidimensionnel, on peut mesurer leur similarité à l'aide de la similitude cosinus :\n",
    "\n",
    "![Similitude Cosine - Formule](./asset/vector_sim.png)\n",
    "\n",
    "Pour deux vecteurs, **a** et **b**, le cosinus de l'angle (θ) est utilisé pour évaluer leur proximité dans un espace vectoriel :\n",
    "\n",
    "- **−1** : Les vecteurs sont opposés, ce qui indique aucune similarité.\n",
    "   *Exemple* : \"nord\" et \"sud\".\n",
    "- **0** : Les vecteurs sont indépendants ou orthogonaux.\n",
    "   *Exemple* : \"chien\" et \"lune\" n'ont aucune relation contextuelle.\n",
    "- **+1** : Les vecteurs sont similaires ou identiques.\n",
    "   *Exemple* : \"heureux\" et \"joyeux\" expriment des émotions positives proches.\n",
    "\n",
    "![Cosinus - Formule](./asset/formule_cosine.png)\n",
    "\n",
    "**||A||** représente la norme Euclidienne du vecteur, qui se calcule comme suit :\n",
    "![Norme Euclidienne](./asset/euclide.png)\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Cas d'utilisation\n",
    "\n",
    "TF-IDF peut être appliqué à divers problèmes en NLP :\n",
    "- Recherche d'information (systèmes de moteurs de recherche).\n",
    "- Classification de documents.\n",
    "- Résumé automatique de texte."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 269,
     "status": "ok",
     "timestamp": 1675066001672,
     "user": {
      "displayName": "Swan Blanc",
      "userId": "06655654812785803318"
     },
     "user_tz": -60
    },
    "id": "V8EPiV807383",
    "outputId": "59b879e6-8af7-407e-a597-baa34a10571c",
    "ExecuteTime": {
     "end_time": "2025-06-17T12:39:22.244285Z",
     "start_time": "2025-06-17T12:39:21.682140Z"
    }
   },
   "source": [
    "print(docs)\n",
    "print(len(docs))"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'docs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[2], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[43mdocs\u001B[49m)\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;28mlen\u001B[39m(docs))\n",
      "\u001B[1;31mNameError\u001B[0m: name 'docs' is not defined"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 238,
     "status": "ok",
     "timestamp": 1675066003300,
     "user": {
      "displayName": "Swan Blanc",
      "userId": "06655654812785803318"
     },
     "user_tz": -60
    },
    "id": "hHbjuiBw-wnu",
    "outputId": "a3ef8442-5386-4221-f1b6-87a23ef3beb2"
   },
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=200)\n",
    "vectors = vectorizer.fit_transform(docs)\n",
    "# liste des mots 't'\n",
    "vectorizer.vocabulary_"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# 6 phrase\n",
    "vectors.toarray()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 345,
     "status": "ok",
     "timestamp": 1675066084676,
     "user": {
      "displayName": "Swan Blanc",
      "userId": "06655654812785803318"
     },
     "user_tz": -60
    },
    "id": "XZ6GPLIB_ed5",
    "outputId": "86ec4e0a-6a62-4d74-b851-3a2c6c649bca"
   },
   "source": [
    "def tfidf_simlarity_search(vectorizer, dataset_matrix, dataset, input_text):\n",
    "    # Vectorise l'entrée textuelle (input_text)\n",
    "    # La méthode `transform` du vectoriseur TF-IDF transforme le texte d'entrée en vecteur sparse (creux),\n",
    "    # qui contient les poids TF-IDF pour chaque mot selon le vocabulaire du dataset.\n",
    "    query_vec = vectorizer.transform([input_text])\n",
    "\n",
    "    # Calcule la similarité cosinus entre la matrice du dataset existant (dataset_matrix)\n",
    "    # et le vecteur de la requête (query_vec).\n",
    "    # La similarité cosinus mesure à quel point deux vecteurs sont proches dans l'espace vectoriel,\n",
    "    # avec une valeur de 1 indiquant une correspondance parfaite.\n",
    "    results = cosine_similarity(dataset_matrix, query_vec).reshape((-1,))\n",
    "\n",
    "    print(f\"Query: {input_text}\")\n",
    "\n",
    "    # Trie les indices des résultats de la similarité dans l'ordre décroissant\n",
    "    # afin d'obtenir les 10 documents les plus pertinents.\n",
    "    # argsort() trie les indices par la valeur associée, et [::-1] inverse cet ordre.\n",
    "    for i in results.argsort()[-10:][::-1]:\n",
    "        # Affiche les indices des documents du dataset les plus similaires (ajuste l'indice pour correspondre à une base 1)\n",
    "        # ainsi que leur contenu.\n",
    "        print(f\"{i + 1} - {dataset[i]}\")\n",
    "\n",
    "\n",
    "query = clean_sentence(\"manger\", nlp)\n",
    "# Recherche les documents les plus similaires à cette requête en utilisant la fonction TF-IDF.\n",
    "tfidf_simlarity_search(vectorizer, vectors, docs, query)\n",
    "\n",
    "# Séparation des résultats pour faciliter la lecture.\n",
    "print(\"----------------------\")\n",
    "\n",
    "# Prépare une nouvelle requête utilisateur, cette fois pour \"envoyé des email\".\n",
    "query = clean_sentence(\"envoyé des email\", nlp)\n",
    "# Recherche des documents similaires avec la nouvelle entrée textuelle.\n",
    "tfidf_simlarity_search(vectorizer, vectors, docs, query)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Classificateur\n",
    "## k-NN : Un Classificateur Simple\n",
    "\n",
    "Le classificateur k-Nearest Neighbor (k-NN) est l'un des algorithmes de classification les plus simples en apprentissage automatique et pour la classification d'images. En réalité, cet algorithme ne \"découvre\" ou \"apprend\" rien.\n",
    "\n",
    "Il repose simplement sur la distance entre les vecteurs de caractéristiques (ici, les intensités brutes des pixels RGB des images).\n",
    "\n",
    "Pour plus de détails, consultez ce [guide utilisateur](https://scikit-learn.org/stable/modules/neighbors.html#nearest-neighbors-classification).\n",
    "\n",
    "![Représentation d'un sac](./asset/knn.png)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 803,
     "status": "ok",
     "timestamp": 1675066342603,
     "user": {
      "displayName": "Swan Blanc",
      "userId": "06655654812785803318"
     },
     "user_tz": -60
    },
    "id": "BGS_MYOEd0--",
    "outputId": "30a54dd8-d448-46a8-f48e-ac3563c9fe20"
   },
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Jeu de données multilabel\n",
    "x = [\"j'aime les pomme vert\", \"les orange sont pas top\", \"une grosse poire\", \"la belle poire orange\"]\n",
    "y = [['apple', 'green'], ['orange'], ['pear', 'green'], ['pear', 'orange']]\n",
    "\n",
    "# Jeu de données de test\n",
    "x_test = [\"pomme vert bio\", \"je suis orange\", \"la belle orange poire\"]\n",
    "y_test = [['apple', 'green'], ['orange'], ['pear', 'orange']]\n",
    "\n",
    "# Encodage des classes en multilabel\n",
    "# Ici, on utilise MultiLabelBinarizer pour transformer les listes de labels en représentations binaires\n",
    "# Chaque classe est représentée comme 0 (absence) ou 1 (présence), formant un tableau binaire par exemples.\n",
    "encoder = MultiLabelBinarizer()\n",
    "y_encoded = encoder.fit_transform(y)  # Encodage des labels du jeu d'entraînement\n",
    "y_test_encoded = encoder.transform(y_test)  # Encodage des labels du jeu de test (sur la base des classes apprises)\n",
    "\n",
    "print(f\"\"\"Encoder\n",
    "{encoder.classes_}\n",
    "----------\n",
    "Train Y encode\n",
    "{y_encoded}\n",
    "----------\n",
    "Test Y encode\n",
    "{y_test_encoded}\n",
    "\"\"\")\n",
    "\n",
    "# Pipeline avec une vectorisation TF-IDF et un classifieur k-NN\n",
    "model_pipeline = Pipeline([\n",
    "    # Étape 1 : Transformation des textes en vecteurs numériques avec TF-IDF\n",
    "    # - TF-IDF (Term Frequency-Inverse Document Frequency) aide à quantifier les mots tout en diminuant le poids des mots plus communs.\n",
    "    # - `max_features=200` limite le vocabulaire à 200 mots les plus fréquents pour éviter le surapprentissage.\n",
    "    # - `ngram_range=(1, 2)` permet de calculer les unigrammes (mots individuels) et les bigrammes (séquences de deux mots).\n",
    "    ('vectorizer', TfidfVectorizer(max_features=200, ngram_range=(1, 2))),\n",
    "\n",
    "    # Étape 2 : Classifieur k plus proches voisins (KNeighborsClassifier)\n",
    "    # - `n_neighbors=3` indique qu'on utilise les 3 voisins les plus proches pour effectuer la classification.\n",
    "    # - `weights='distance'` donne plus de poids aux voisins plus proches lors de la décision.\n",
    "    ('classifier', KNeighborsClassifier(n_neighbors=3, weights='distance'))\n",
    "    ])\n",
    "\n",
    "# Entraînement du modèle\n",
    "# `fit` entraîne le pipeline entier (vectorisation suivie de la classification) sur les données d'entraînement.\n",
    "model_pipeline.fit(x, y_encoded)\n",
    "\n",
    "# Génération des prédictions et évaluation du modèle sur les données de test\n",
    "# - `predict` applique le traitement aux données de test et génère les prédictions sous forme binaire\n",
    "predictions = model_pipeline.predict(x_test)\n",
    "\n",
    "# Affichage des résultats\n",
    "# 1) Calcul et affichage de la précision du modèle sur les données de test.\n",
    "#    La fonction `accuracy_score` évalue la similarité entre les prédictions et les labels réels.\n",
    "print(f\"Test Accuracy: {accuracy_score(y_test_encoded, predictions):.2f}\")\n",
    "\n",
    "# 2) Affichage d'un rapport de classification détaillé.\n",
    "#    La fonction `classification_report` fournit des métriques comme la précision, le rappel et le F1-score\n",
    "#    pour chaque classe cible (interprétée à partir des classes encodées).\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test_encoded,\n",
    "                            predictions,\n",
    "                            zero_division=0,\n",
    "                            target_names=encoder.classes_))"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMq1mqHDjZaWCrXVBX0jN/f",
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
